{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whale/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(19)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, \n",
    "                  optimizer = keras.optimizers.Adadelta(), \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 231s - loss: 0.6793 - acc: 0.7856 - val_loss: 0.0959 - val_acc: 0.9731\n",
      "Epoch 2/10\n",
      " - 224s - loss: 0.1951 - acc: 0.9480 - val_loss: 0.0672 - val_acc: 0.9815\n",
      "Epoch 3/10\n",
      " - 226s - loss: 0.1441 - acc: 0.9625 - val_loss: 0.0619 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      " - 223s - loss: 0.1191 - acc: 0.9693 - val_loss: 0.0537 - val_acc: 0.9856\n",
      "Epoch 5/10\n",
      " - 228s - loss: 0.1027 - acc: 0.9740 - val_loss: 0.0459 - val_acc: 0.9866\n",
      "Epoch 6/10\n",
      " - 239s - loss: 0.0913 - acc: 0.9757 - val_loss: 0.0431 - val_acc: 0.9884\n",
      "Epoch 7/10\n",
      " - 233s - loss: 0.0844 - acc: 0.9777 - val_loss: 0.0563 - val_acc: 0.9852\n",
      "Epoch 8/10\n",
      " - 242s - loss: 0.0770 - acc: 0.9796 - val_loss: 0.0516 - val_acc: 0.9874\n",
      "Epoch 9/10\n",
      " - 255s - loss: 0.0720 - acc: 0.9817 - val_loss: 0.0467 - val_acc: 0.9894\n",
      "Epoch 10/10\n",
      " - 231s - loss: 0.0673 - acc: 0.9829 - val_loss: 0.0382 - val_acc: 0.9900\n",
      "Baseline Error: 1.00%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 200, verbose = 2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.6555 - acc: 0.7867 - val_loss: 0.1776 - val_acc: 0.9479\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.1389 - acc: 0.9568 - val_loss: 0.0808 - val_acc: 0.9736\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0981 - acc: 0.9694 - val_loss: 0.0651 - val_acc: 0.9804\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0785 - acc: 0.9751 - val_loss: 0.0477 - val_acc: 0.9844\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0645 - acc: 0.9794 - val_loss: 0.0442 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0566 - acc: 0.9824 - val_loss: 0.0443 - val_acc: 0.9848\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0517 - acc: 0.9835 - val_loss: 0.0508 - val_acc: 0.9835\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 172s 3ms/step - loss: 0.0458 - acc: 0.9858 - val_loss: 0.0321 - val_acc: 0.9895\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0419 - acc: 0.9868 - val_loss: 0.0481 - val_acc: 0.9835\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 152s 3ms/step - loss: 0.0398 - acc: 0.9877 - val_loss: 0.0280 - val_acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb46daa0978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=512,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.02740\n",
      "accuracy: 99.11%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0, )\n",
    "print(f'loss: {scores[0]: 0.5f}')\n",
    "print(f'accuracy:{scores[1]*100: 0.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
